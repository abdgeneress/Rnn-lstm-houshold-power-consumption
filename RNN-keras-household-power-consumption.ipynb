{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import numpy as np # linear algebra\n",
    "from scipy.stats import randint\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv), data manipulation as in SQL\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "from sklearn.model_selection import train_test_split # to split the data into two parts\n",
    "#from sklearn.cross_validation import KFold # use for cross validation\n",
    "from sklearn.preprocessing import StandardScaler # for normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline # pipeline making\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics # for the check the error and accuracy of the model\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "\n",
    "\n",
    "#for Deep-learing:\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Deep learning\n"
     ]
    }
   ],
   "source": [
    "cd D:\\Deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('household_power_consumption.txt', sep=';', \n",
    "                 parse_dates={'dt' : ['Date', 'Time']}, infer_datetime_format=True, \n",
    "                 low_memory=False, na_values=['nan','?'], index_col='dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Global_active_power</th>\n",
       "      <th>Global_reactive_power</th>\n",
       "      <th>Voltage</th>\n",
       "      <th>Global_intensity</th>\n",
       "      <th>Sub_metering_1</th>\n",
       "      <th>Sub_metering_2</th>\n",
       "      <th>Sub_metering_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:24:00</th>\n",
       "      <td>4.216</td>\n",
       "      <td>0.418</td>\n",
       "      <td>234.84</td>\n",
       "      <td>18.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:25:00</th>\n",
       "      <td>5.360</td>\n",
       "      <td>0.436</td>\n",
       "      <td>233.63</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:26:00</th>\n",
       "      <td>5.374</td>\n",
       "      <td>0.498</td>\n",
       "      <td>233.29</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:27:00</th>\n",
       "      <td>5.388</td>\n",
       "      <td>0.502</td>\n",
       "      <td>233.74</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-12-16 17:28:00</th>\n",
       "      <td>3.666</td>\n",
       "      <td>0.528</td>\n",
       "      <td>235.68</td>\n",
       "      <td>15.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
       "dt                                                                         \n",
       "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "dt                                                                      \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "dt                                   \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data evaluation\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                      Global_active_power  Global_reactive_power  Voltage  \\\n",
       "dt                                                                         \n",
       "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
       "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
       "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
       "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
       "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
       "2006-12-16 17:29:00                3.520                  0.522   235.02   \n",
       "2006-12-16 17:30:00                3.702                  0.520   235.09   \n",
       "2006-12-16 17:31:00                3.700                  0.520   235.22   \n",
       "2006-12-16 17:32:00                3.668                  0.510   233.99   \n",
       "2006-12-16 17:33:00                3.662                  0.510   233.86   \n",
       "2006-12-16 17:34:00                4.448                  0.498   232.86   \n",
       "2006-12-16 17:35:00                5.412                  0.470   232.78   \n",
       "2006-12-16 17:36:00                5.224                  0.478   232.99   \n",
       "2006-12-16 17:37:00                5.268                  0.398   232.91   \n",
       "2006-12-16 17:38:00                4.054                  0.422   235.24   \n",
       "2006-12-16 17:39:00                3.384                  0.282   237.14   \n",
       "2006-12-16 17:40:00                3.270                  0.152   236.73   \n",
       "2006-12-16 17:41:00                3.430                  0.156   237.06   \n",
       "2006-12-16 17:42:00                3.266                  0.000   237.13   \n",
       "2006-12-16 17:43:00                3.728                  0.000   235.84   \n",
       "2006-12-16 17:44:00                5.894                  0.000   232.69   \n",
       "2006-12-16 17:45:00                7.706                  0.000   230.98   \n",
       "2006-12-16 17:46:00                7.026                  0.000   232.21   \n",
       "2006-12-16 17:47:00                5.174                  0.000   234.19   \n",
       "2006-12-16 17:48:00                4.474                  0.000   234.96   \n",
       "2006-12-16 17:49:00                3.248                  0.000   236.66   \n",
       "2006-12-16 17:50:00                3.236                  0.000   235.84   \n",
       "2006-12-16 17:51:00                3.228                  0.000   235.60   \n",
       "2006-12-16 17:52:00                3.258                  0.000   235.49   \n",
       "2006-12-16 17:53:00                3.178                  0.000   235.28   \n",
       "...                                  ...                    ...      ...   \n",
       "2010-11-26 20:33:00                0.978                  0.000   240.28   \n",
       "2010-11-26 20:34:00                0.968                  0.000   237.57   \n",
       "2010-11-26 20:35:00                0.960                  0.000   238.01   \n",
       "2010-11-26 20:36:00                0.964                  0.000   238.07   \n",
       "2010-11-26 20:37:00                0.980                  0.000   237.90   \n",
       "2010-11-26 20:38:00                0.976                  0.096   236.97   \n",
       "2010-11-26 20:39:00                0.984                  0.100   238.16   \n",
       "2010-11-26 20:40:00                0.986                  0.102   238.92   \n",
       "2010-11-26 20:41:00                0.990                  0.106   239.57   \n",
       "2010-11-26 20:42:00                0.988                  0.106   239.60   \n",
       "2010-11-26 20:43:00                0.988                  0.106   239.64   \n",
       "2010-11-26 20:44:00                0.982                  0.102   238.69   \n",
       "2010-11-26 20:45:00                0.972                  0.092   238.32   \n",
       "2010-11-26 20:46:00                0.908                  0.000   238.53   \n",
       "2010-11-26 20:47:00                0.910                  0.000   238.71   \n",
       "2010-11-26 20:48:00                0.912                  0.000   239.25   \n",
       "2010-11-26 20:49:00                0.948                  0.000   238.16   \n",
       "2010-11-26 20:50:00                1.198                  0.128   238.11   \n",
       "2010-11-26 20:51:00                1.024                  0.106   238.84   \n",
       "2010-11-26 20:52:00                0.946                  0.000   239.05   \n",
       "2010-11-26 20:53:00                0.944                  0.000   238.72   \n",
       "2010-11-26 20:54:00                0.946                  0.000   239.31   \n",
       "2010-11-26 20:55:00                0.946                  0.000   239.74   \n",
       "2010-11-26 20:56:00                0.942                  0.000   239.41   \n",
       "2010-11-26 20:57:00                0.946                  0.000   240.33   \n",
       "2010-11-26 20:58:00                0.946                  0.000   240.43   \n",
       "2010-11-26 20:59:00                0.944                  0.000   240.00   \n",
       "2010-11-26 21:00:00                0.938                  0.000   239.82   \n",
       "2010-11-26 21:01:00                0.934                  0.000   239.70   \n",
       "2010-11-26 21:02:00                0.932                  0.000   239.55   \n",
       "\n",
       "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
       "dt                                                                      \n",
       "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
       "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
       "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
       "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
       "2006-12-16 17:29:00              15.0             0.0             2.0   \n",
       "2006-12-16 17:30:00              15.8             0.0             1.0   \n",
       "2006-12-16 17:31:00              15.8             0.0             1.0   \n",
       "2006-12-16 17:32:00              15.8             0.0             1.0   \n",
       "2006-12-16 17:33:00              15.8             0.0             2.0   \n",
       "2006-12-16 17:34:00              19.6             0.0             1.0   \n",
       "2006-12-16 17:35:00              23.2             0.0             1.0   \n",
       "2006-12-16 17:36:00              22.4             0.0             1.0   \n",
       "2006-12-16 17:37:00              22.6             0.0             2.0   \n",
       "2006-12-16 17:38:00              17.6             0.0             1.0   \n",
       "2006-12-16 17:39:00              14.2             0.0             0.0   \n",
       "2006-12-16 17:40:00              13.8             0.0             0.0   \n",
       "2006-12-16 17:41:00              14.4             0.0             0.0   \n",
       "2006-12-16 17:42:00              13.8             0.0             0.0   \n",
       "2006-12-16 17:43:00              16.4             0.0             0.0   \n",
       "2006-12-16 17:44:00              25.4             0.0             0.0   \n",
       "2006-12-16 17:45:00              33.2             0.0             0.0   \n",
       "2006-12-16 17:46:00              30.6             0.0             0.0   \n",
       "2006-12-16 17:47:00              22.0             0.0             0.0   \n",
       "2006-12-16 17:48:00              19.4             0.0             0.0   \n",
       "2006-12-16 17:49:00              13.6             0.0             0.0   \n",
       "2006-12-16 17:50:00              13.6             0.0             0.0   \n",
       "2006-12-16 17:51:00              13.6             0.0             0.0   \n",
       "2006-12-16 17:52:00              13.8             0.0             0.0   \n",
       "2006-12-16 17:53:00              13.4             0.0             0.0   \n",
       "...                               ...             ...             ...   \n",
       "2010-11-26 20:33:00               4.0             0.0             1.0   \n",
       "2010-11-26 20:34:00               4.0             0.0             1.0   \n",
       "2010-11-26 20:35:00               4.0             0.0             1.0   \n",
       "2010-11-26 20:36:00               4.0             0.0             1.0   \n",
       "2010-11-26 20:37:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:38:00               4.0             0.0             2.0   \n",
       "2010-11-26 20:39:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:40:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:41:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:42:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:43:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:44:00               4.0             0.0             1.0   \n",
       "2010-11-26 20:45:00               4.0             0.0             2.0   \n",
       "2010-11-26 20:46:00               3.8             0.0             1.0   \n",
       "2010-11-26 20:47:00               3.8             0.0             1.0   \n",
       "2010-11-26 20:48:00               3.8             0.0             1.0   \n",
       "2010-11-26 20:49:00               4.0             0.0             1.0   \n",
       "2010-11-26 20:50:00               5.0             0.0             1.0   \n",
       "2010-11-26 20:51:00               4.2             0.0             1.0   \n",
       "2010-11-26 20:52:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:53:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:54:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:55:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:56:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:57:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:58:00               4.0             0.0             0.0   \n",
       "2010-11-26 20:59:00               4.0             0.0             0.0   \n",
       "2010-11-26 21:00:00               3.8             0.0             0.0   \n",
       "2010-11-26 21:01:00               3.8             0.0             0.0   \n",
       "2010-11-26 21:02:00               3.8             0.0             0.0   \n",
       "\n",
       "                     Sub_metering_3  \n",
       "dt                                   \n",
       "2006-12-16 17:24:00            17.0  \n",
       "2006-12-16 17:25:00            16.0  \n",
       "2006-12-16 17:26:00            17.0  \n",
       "2006-12-16 17:27:00            17.0  \n",
       "2006-12-16 17:28:00            17.0  \n",
       "2006-12-16 17:29:00            17.0  \n",
       "2006-12-16 17:30:00            17.0  \n",
       "2006-12-16 17:31:00            17.0  \n",
       "2006-12-16 17:32:00            17.0  \n",
       "2006-12-16 17:33:00            16.0  \n",
       "2006-12-16 17:34:00            17.0  \n",
       "2006-12-16 17:35:00            17.0  \n",
       "2006-12-16 17:36:00            16.0  \n",
       "2006-12-16 17:37:00            17.0  \n",
       "2006-12-16 17:38:00            17.0  \n",
       "2006-12-16 17:39:00            17.0  \n",
       "2006-12-16 17:40:00            17.0  \n",
       "2006-12-16 17:41:00            17.0  \n",
       "2006-12-16 17:42:00            18.0  \n",
       "2006-12-16 17:43:00            17.0  \n",
       "2006-12-16 17:44:00            16.0  \n",
       "2006-12-16 17:45:00            17.0  \n",
       "2006-12-16 17:46:00            16.0  \n",
       "2006-12-16 17:47:00            17.0  \n",
       "2006-12-16 17:48:00            17.0  \n",
       "2006-12-16 17:49:00            17.0  \n",
       "2006-12-16 17:50:00            17.0  \n",
       "2006-12-16 17:51:00            17.0  \n",
       "2006-12-16 17:52:00            17.0  \n",
       "2006-12-16 17:53:00            17.0  \n",
       "...                             ...  \n",
       "2010-11-26 20:33:00             0.0  \n",
       "2010-11-26 20:34:00             0.0  \n",
       "2010-11-26 20:35:00             0.0  \n",
       "2010-11-26 20:36:00             0.0  \n",
       "2010-11-26 20:37:00             0.0  \n",
       "2010-11-26 20:38:00             0.0  \n",
       "2010-11-26 20:39:00             0.0  \n",
       "2010-11-26 20:40:00             0.0  \n",
       "2010-11-26 20:41:00             0.0  \n",
       "2010-11-26 20:42:00             0.0  \n",
       "2010-11-26 20:43:00             0.0  \n",
       "2010-11-26 20:44:00             0.0  \n",
       "2010-11-26 20:45:00             0.0  \n",
       "2010-11-26 20:46:00             0.0  \n",
       "2010-11-26 20:47:00             0.0  \n",
       "2010-11-26 20:48:00             0.0  \n",
       "2010-11-26 20:49:00             0.0  \n",
       "2010-11-26 20:50:00             0.0  \n",
       "2010-11-26 20:51:00             0.0  \n",
       "2010-11-26 20:52:00             0.0  \n",
       "2010-11-26 20:53:00             0.0  \n",
       "2010-11-26 20:54:00             0.0  \n",
       "2010-11-26 20:55:00             0.0  \n",
       "2010-11-26 20:56:00             0.0  \n",
       "2010-11-26 20:57:00             0.0  \n",
       "2010-11-26 20:58:00             0.0  \n",
       "2010-11-26 20:59:00             0.0  \n",
       "2010-11-26 21:00:00             0.0  \n",
       "2010-11-26 21:01:00             0.0  \n",
       "2010-11-26 21:02:00             0.0  \n",
       "\n",
       "[2075259 rows x 7 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power      float64\n",
       "Global_reactive_power    float64\n",
       "Voltage                  float64\n",
       "Global_intensity         float64\n",
       "Sub_metering_1           float64\n",
       "Sub_metering_2           float64\n",
       "Sub_metering_3           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2075259, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Global_active_power', 'Global_reactive_power', 'Voltage',\n",
       "       'Global_intensity', 'Sub_metering_1', 'Sub_metering_2',\n",
       "       'Sub_metering_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with missing values 'nan' with a test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finding all columns that have nan:\n",
    "\n",
    "droping_list_all=[]\n",
    "for j in range(0,7):\n",
    "    if not df.iloc[:, j].notnull().all():\n",
    "        droping_list_all.append(j)        \n",
    "        #print(df.iloc[:,j].unique())\n",
    "droping_list_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling nan with mean in any columns\n",
    "\n",
    "for j in range(0,7):        \n",
    "        df.iloc[:,j]=df.iloc[:,j].fillna(df.iloc[:,j].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Global_active_power      0\n",
       "Global_reactive_power    0\n",
       "Voltage                  0\n",
       "Global_intensity         0\n",
       "Sub_metering_1           0\n",
       "Sub_metering_2           0\n",
       "Sub_metering_3           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Data Preparation and feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    dff = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(dff.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "        # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "            cols.append(dff.shift(-i))\n",
    "            if i == 0:\n",
    "                names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "            else:\n",
    "                names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34589, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## resampling of data over hour\n",
    "df_resample = df.resample('h').mean() \n",
    "df_resample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.636816   0.295738   0.337945   0.631157        0.0   0.011366   \n",
      "2   0.545045   0.103358   0.335501   0.541487        0.0   0.144652   \n",
      "3   0.509006   0.110073   0.283802   0.502152        0.0   0.030869   \n",
      "4   0.488550   0.096987   0.315987   0.481110        0.0   0.000000   \n",
      "5   0.455597   0.099010   0.434417   0.449904        0.0   0.008973   \n",
      "\n",
      "   var7(t-1)   var1(t)  \n",
      "1   0.782418  0.545045  \n",
      "2   0.782676  0.509006  \n",
      "3   0.774169  0.488550  \n",
      "4   0.778809  0.455597  \n",
      "5   0.798917  0.322555  \n"
     ]
    }
   ],
   "source": [
    "## scale all features in range of [0,1].\n",
    "\n",
    "## If you would like to train based on the resampled data (over hour), then used below\n",
    "values = df_resample.values \n",
    "\n",
    "\n",
    "## full data without resampling\n",
    "#values = df.values\n",
    "\n",
    "# integer encode direction\n",
    "# ensure all data is float\n",
    "#values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[8,9,10,11,12,13]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the rest of data to train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 7) (8760,) (25828, 1, 7) (25828,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "\n",
    "n_train_time = 365*24\n",
    "train = values[:n_train_time, :]\n",
    "test = values[n_train_time:, :]\n",
    "##test = values[n_train_time:n_test_time, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "# We reshaped the input into the 3D format as expected by LSTMs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 8760 samples, validate on 25828 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 0.0206 - val_loss: 0.0119\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.0126 - val_loss: 0.0107\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.0116 - val_loss: 0.0097\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.0109 - val_loss: 0.0094\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.0106 - val_loss: 0.0093\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0103 - val_loss: 0.0093\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "#    model.add(LSTM(70))\n",
    "#    model.add(Dropout(0.3))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "\n",
    "\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=20, batch_size=70, validation_data=(test_X, test_y), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.620\n"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], 7))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat, test_X[:, -6:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, -6:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
